/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => SpeechToTextPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian = require("obsidian");
var SpeechToTextPlugin = class extends import_obsidian.Plugin {
  constructor() {
    super(...arguments);
    this.isTranscribing = false;
    this.currentStream = null;
    this.audioContext = null;
    this.audioProcessor = null;
    this.audioSource = null;
    this.ribbonIconEl = null;
    this.statusBarItem = null;
    this.activeSourceName = null;
    this.sampleBuffers = [];
    this.samplesCollected = 0;
    this.targetSampleRate = 16e3;
    this.pendingControllers = [];
  }
  async onload() {
    var _a;
    this.settings = await this.loadSettings();
    this.addSettingTab(new STTSettingTab(this.app, this));
    this.injectStyles();
    this.statusBarItem = this.addStatusBarItem();
    this.updateStatusBar("STT inativo");
    this.ribbonIconEl = this.addRibbonIcon("mic", "Iniciar transcri\xE7\xE3o", () => {
      if (this.isTranscribing) {
        this.stopTranscription();
        return;
      }
      new AudioSourceSelectorModal(this.app, (source) => {
        this.startTranscription(source);
      }).open();
    });
    (_a = this.ribbonIconEl) == null ? void 0 : _a.addClass("stt-ribbon-icon");
    this.setRibbonTooltip("Iniciar transcri\xE7\xE3o");
    this.addCommand({
      id: "start-transcription",
      name: "Iniciar transcri\xE7\xE3o",
      callback: () => {
        if (this.isTranscribing) {
          new import_obsidian.Notice("A transcri\xE7\xE3o j\xE1 est\xE1 em andamento.");
          return;
        }
        new AudioSourceSelectorModal(this.app, (source) => {
          this.startTranscription(source);
        }).open();
      }
    });
  }
  async startTranscription(source) {
    if (this.isTranscribing)
      return;
    new import_obsidian.Notice(`Iniciando transcri\xE7\xE3o da fonte: ${source.name}`);
    this.isTranscribing = true;
    try {
      let stream;
      if (source.id.startsWith("window:") || source.id.startsWith("screen:")) {
        stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            mandatory: {
              chromeMediaSource: "desktop",
              chromeMediaSourceId: source.id
            }
          },
          video: {
            mandatory: {
              chromeMediaSource: "desktop",
              chromeMediaSourceId: source.id
            }
          }
        });
      } else {
        stream = await navigator.mediaDevices.getUserMedia({
          audio: { deviceId: { exact: source.id } },
          video: false
        });
      }
      const audioTracks = stream.getAudioTracks();
      if (!audioTracks || audioTracks.length === 0) {
        throw new Error("Nenhuma trilha de \xE1udio encontrada na fonte selecionada.");
      }
      this.currentStream = stream;
      this.activeSourceName = source.name;
      this.markRecording(true);
      await this.startPCMRecorder(stream);
    } catch (error) {
      console.error("Speech-to-Text: Falha ao iniciar transcri\xE7\xE3o:", error);
      new import_obsidian.Notice(`Erro ao acessar a fonte de \xE1udio: ${(error == null ? void 0 : error.message) || error}`);
      this.stopTranscription();
    }
  }
  stopTranscription() {
    if (!this.isTranscribing)
      return;
    if (this.audioProcessor) {
      this.audioProcessor.disconnect();
      this.audioProcessor.onaudioprocess = null;
      this.audioProcessor = null;
    }
    if (this.audioSource) {
      this.audioSource.disconnect();
      this.audioSource = null;
    }
    if (this.audioContext) {
      this.audioContext.close().catch(() => null);
      this.audioContext = null;
    }
    if (this.currentStream) {
      this.currentStream.getTracks().forEach((track) => track.stop());
      this.currentStream = null;
    }
    this.activeSourceName = null;
    this.markRecording(false);
    this.sampleBuffers = [];
    this.samplesCollected = 0;
    this.pendingControllers.forEach((controller) => controller.abort());
    this.pendingControllers = [];
    this.isTranscribing = false;
    new import_obsidian.Notice("Transcri\xE7\xE3o interrompida.");
  }
  async startPCMRecorder(stream) {
    if (this.audioContext) {
      this.stopTranscription();
    }
    const audioContext = new AudioContext({ sampleRate: this.targetSampleRate });
    this.targetSampleRate = audioContext.sampleRate;
    this.audioContext = audioContext;
    const sourceNode = audioContext.createMediaStreamSource(stream);
    this.audioSource = sourceNode;
    const processor = audioContext.createScriptProcessor(4096, 1, 1);
    this.audioProcessor = processor;
    let baseOffset = null;
    const editorGetter = () => {
      var _a;
      return (_a = this.app.workspace.activeEditor) == null ? void 0 : _a.editor;
    };
    const samplesPerChunk = Math.max(1, Math.round(this.targetSampleRate * this.settings.chunkMs / 1e3));
    processor.onaudioprocess = async (event) => {
      const channelData = event.inputBuffer.getChannelData(0);
      const clone = new Float32Array(channelData.length);
      clone.set(channelData);
      this.sampleBuffers.push(clone);
      this.samplesCollected += clone.length;
      while (this.samplesCollected >= samplesPerChunk) {
        const chunkSamples = this.takeSamples(samplesPerChunk);
        const wavBlob = this.encodeWav(chunkSamples, this.targetSampleRate);
        try {
          const transcript = await this.sendChunk(wavBlob, "audio/wav");
          const editor = editorGetter();
          if (!transcript || !editor)
            continue;
          if (baseOffset === null) {
            baseOffset = editor.posToOffset(editor.getCursor());
          }
          const insertPos = editor.offsetToPos(baseOffset);
          editor.replaceRange(transcript, insertPos);
          baseOffset += transcript.length;
          editor.setCursor(editor.offsetToPos(baseOffset));
        } catch (sendError) {
          console.error("Speech-to-Text: Erro ao enviar chunk PCM para STT:", sendError);
          new import_obsidian.Notice(`Erro ao transcrever chunk: ${(sendError == null ? void 0 : sendError.message) || sendError}`);
          this.stopTranscription();
        }
      }
    };
    sourceNode.connect(processor);
    processor.connect(audioContext.destination);
    console.log("Speech-to-Text: Captura PCM iniciada com SampleRate", this.targetSampleRate);
  }
  takeSamples(count) {
    const out = new Float32Array(count);
    let offset = 0;
    while (offset < count && this.sampleBuffers.length > 0) {
      const buffer = this.sampleBuffers[0];
      const needed = count - offset;
      if (buffer.length <= needed) {
        out.set(buffer, offset);
        offset += buffer.length;
        this.sampleBuffers.shift();
      } else {
        out.set(buffer.subarray(0, needed), offset);
        this.sampleBuffers[0] = buffer.subarray(needed);
        offset += needed;
      }
    }
    this.samplesCollected -= count;
    return out;
  }
  encodeWav(samples, sampleRate) {
    const buffer = new ArrayBuffer(44 + samples.length * 2);
    const view = new DataView(buffer);
    const writeString = (offset, str) => {
      for (let i = 0; i < str.length; i++) {
        view.setUint8(offset + i, str.charCodeAt(i));
      }
    };
    const pcm = new Int16Array(samples.length);
    for (let i = 0; i < samples.length; i++) {
      const s = Math.max(-1, Math.min(1, samples[i]));
      pcm[i] = s < 0 ? s * 32768 : s * 32767;
    }
    writeString(0, "RIFF");
    view.setUint32(4, 36 + pcm.length * 2, true);
    writeString(8, "WAVE");
    writeString(12, "fmt ");
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, "data");
    view.setUint32(40, pcm.length * 2, true);
    for (let i = 0; i < pcm.length; i++) {
      view.setInt16(44 + i * 2, pcm[i], true);
    }
    return new Blob([buffer], { type: "audio/wav" });
  }
  async sendChunk(blob, mimeTypeUsed) {
    var _a, _b;
    if (!this.settings.endpointUrl) {
      throw new Error("Configure o endpoint STT nas configura\xE7\xF5es do plugin.");
    }
    const controller = new AbortController();
    this.pendingControllers.push(controller);
    const headers = {};
    if (!this.settings.useFormData) {
      headers["Content-Type"] = mimeTypeUsed;
    }
    if (this.settings.apiKey) {
      headers["Authorization"] = `Bearer ${this.settings.apiKey}`;
    }
    const body = this.settings.useFormData ? (() => {
      const form = new FormData();
      form.append(this.settings.fileField || "file", blob, "audio.wav");
      if (this.settings.model) {
        form.append("model", this.settings.model);
      }
      if (this.settings.language) {
        form.append("language", this.settings.language);
      }
      return form;
    })() : blob;
    const response = await fetch(this.settings.endpointUrl, {
      method: "POST",
      headers,
      body,
      signal: controller.signal
    });
    this.pendingControllers = this.pendingControllers.filter((c) => c !== controller);
    if (!response.ok) {
      const text = await response.text();
      throw new Error(`HTTP ${response.status}: ${text}`);
    }
    const contentType = response.headers.get("Content-Type") || "";
    if (contentType.includes("application/json")) {
      const json = await response.json();
      const field = this.settings.textField || "text";
      const result = (_b = (_a = json[field]) != null ? _a : json.transcript) != null ? _b : "";
      return typeof result === "string" ? result : JSON.stringify(result);
    }
    return await response.text();
  }
  async loadSettings() {
    const defaultSettings = {
      endpointUrl: "",
      apiKey: "",
      useFormData: true,
      model: "",
      language: "",
      fileField: "file",
      textField: "text",
      chunkMs: 4e3
    };
    const loaded = await this.loadData();
    return Object.assign({}, defaultSettings, loaded);
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
  onunload() {
    this.stopTranscription();
    const style = document.getElementById("stt-plugin-styles");
    if (style)
      style.remove();
  }
  markRecording(active) {
    var _a, _b;
    if (active) {
      (_a = this.ribbonIconEl) == null ? void 0 : _a.addClass("stt-recording");
      const source = this.activeSourceName ? ` | ${this.activeSourceName}` : "";
      const tooltip = `Parar transcri\xE7\xE3o
[REC] Gravando${source ? `
Fonte: ${this.activeSourceName}` : ""}`;
      this.setRibbonTooltip(tooltip);
      this.updateStatusBar(`[REC] Gravando${source ? ` | Fonte: ${this.activeSourceName}` : ""}`);
    } else {
      (_b = this.ribbonIconEl) == null ? void 0 : _b.removeClass("stt-recording");
      this.setRibbonTooltip("Iniciar transcri\xE7\xE3o");
      this.updateStatusBar("STT inativo");
    }
  }
  setRibbonTooltip(text) {
    if (!this.ribbonIconEl)
      return;
    this.ribbonIconEl.setAttribute("aria-label", text);
    this.ribbonIconEl.setAttribute("data-tooltip", text);
  }
  updateStatusBar(text) {
    if (this.statusBarItem) {
      this.statusBarItem.setText(text);
    }
  }
  injectStyles() {
    const style = document.createElement("style");
    style.id = "stt-plugin-styles";
    style.textContent = `
        .stt-ribbon-icon.stt-recording {
            color: var(--text-accent);
            background: var(--background-modifier-success);
            border-radius: 6px;
        }
        .tooltip {
            text-align: left;
            white-space: pre-wrap;
            word-wrap: break-word;
            max-width: 320px;
        }
        .stt-source-modal .source-row {
            display: flex;
            flex-direction: column;
            gap: 6px;
            margin-bottom: 16px;
        }
        .stt-source-modal {
            padding: 12px 16px 16px 16px;
        }
        .stt-source-modal h2 {
            margin-top: 4px;
            margin-bottom: 10px;
            font-size: 20px;
            font-weight: 700;
            color: var(--text-normal);
        }
        .stt-divider {
            border-top: 1px solid var(--background-modifier-border);
            margin: 6px 0 14px 0;
        }
        .stt-field {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }
        .stt-label-row {
            display: flex;
            justify-content: space-between;
            align-items: baseline;
            gap: 12px;
        }
        .stt-label {
            font-weight: 600;
            font-size: 16px;
            color: var(--text-normal);
        }
        .stt-status {
            color: var(--text-faint);
            font-size: 12px;
        }
        .stt-help {
            color: var(--text-muted);
            font-size: 13px;
        }
        .stt-actions {
            margin-top: 14px;
            display: flex;
            justify-content: flex-start;
        }
        .stt-source-modal .status {
            color: var(--text-faint);
            font-size: 12px;
        }
        .stt-source-modal select {
            width: 100%;
            max-width: 260px;
        }
        `;
    document.head.appendChild(style);
  }
};
var AudioSourceSelectorModal = class extends import_obsidian.Modal {
  constructor(app, onSubmit) {
    super(app);
    this.isLoading = true;
    this.selectEl = null;
    this.startButton = null;
    this.statusText = null;
    this.sources = [];
    this.onSubmit = onSubmit;
  }
  async onOpen() {
    const { contentEl } = this;
    contentEl.empty();
    contentEl.addClass("stt-source-modal");
    contentEl.createEl("h2", { text: "Selecione a Fonte de \xC1udio" });
    contentEl.createDiv({ cls: "stt-divider" });
    const field = contentEl.createDiv({ cls: "stt-field" });
    const labelRow = field.createDiv({ cls: "stt-label-row" });
    labelRow.createEl("div", { text: "Fonte de \xE1udio", cls: "stt-label" });
    this.statusText = labelRow.createEl("div", { cls: "stt-status", text: "Varredura do sistema..." });
    field.createEl("div", {
      text: "Escolha uma janela/tela ou microfone para capturar o \xE1udio.",
      cls: "stt-help"
    });
    this.selectEl = field.createEl("select", { cls: "dropdown" });
    const actions = contentEl.createDiv({ cls: "stt-actions" });
    this.startButton = actions.createEl("button", { text: "Iniciar Transcri\xE7\xE3o", cls: "mod-cta" });
    this.selectEl.disabled = true;
    this.startButton.disabled = true;
    this.startButton.onclick = () => {
      var _a;
      const selectedSourceId = (_a = this.selectEl) == null ? void 0 : _a.value;
      const selectedSource = this.sources.find((s) => s.id === selectedSourceId);
      if (selectedSource) {
        this.onSubmit(selectedSource);
        this.close();
      }
    };
    await this.populateSources();
  }
  async populateSources() {
    var _a, _b, _c;
    console.log("Speech-to-Text: Populando fontes de \xE1udio...");
    const electron = window.require("electron");
    const remote = electron.remote;
    if (!remote || !remote.desktopCapturer) {
      console.error("Speech-to-Text: M\xF3dulo desktopCapturer do Electron n\xE3o encontrado.");
      (_a = this.statusText) == null ? void 0 : _a.setText("Erro: N\xE3o foi poss\xEDvel carregar o m\xF3dulo para captura de tela.");
      return;
    }
    const { desktopCapturer } = remote;
    const audioSources = [];
    try {
      const sources = await desktopCapturer.getSources({ types: ["window", "screen"] });
      sources.forEach((source) => {
        if (source.name && !source.name.includes("Obsidian")) {
          audioSources.push({ id: source.id, name: `Janela: ${source.name}` });
        }
      });
    } catch (error) {
      console.error("Speech-to-Text: Erro ao buscar fontes do desktop:", error);
    }
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter((device) => device.kind === "audioinput");
      audioInputs.forEach((device, index) => {
        audioSources.push({ id: device.deviceId, name: device.label || `Microfone ${index + 1}` });
      });
    } catch (error) {
      console.error("Speech-to-Text: Erro ao buscar dispositivos de m\xEDdia:", error);
    }
    this.sources = audioSources;
    if (audioSources.length === 0) {
      (_b = this.statusText) == null ? void 0 : _b.setText("Nenhuma fonte de \xE1udio encontrada. Verifique permiss\xF5es.");
      return;
    }
    if (this.selectEl) {
      this.selectEl.empty();
      audioSources.forEach((source) => {
        var _a2;
        (_a2 = this.selectEl) == null ? void 0 : _a2.createEl("option", { text: source.name, value: source.id });
      });
      this.selectEl.disabled = false;
    }
    if (this.startButton) {
      this.startButton.disabled = false;
    }
    (_c = this.statusText) == null ? void 0 : _c.setText("Fontes carregadas");
  }
  onClose() {
    const { contentEl } = this;
    contentEl.empty();
  }
};
var STTSettingTab = class extends import_obsidian.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Configura\xE7\xF5es do Speech to Text (API externa)" });
    new import_obsidian.Setting(containerEl).setName("Endpoint STT (HTTP)").setDesc("URL que receber\xE1 o \xE1udio e retornar\xE1 o texto.").addText(
      (text) => text.setPlaceholder("https://minha-api.stt/transcribe").setValue(this.plugin.settings.endpointUrl).onChange(async (value) => {
        this.plugin.settings.endpointUrl = value.trim();
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("API Key (opcional)").setDesc("Enviada como Authorization: Bearer <chave>.").addText(
      (text) => text.setPlaceholder("chave-de-api").setValue(this.plugin.settings.apiKey).onChange(async (value) => {
        this.plugin.settings.apiKey = value.trim();
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("Modelo (ex.: whisper-large-v3)").setDesc("Algumas APIs exigem o campo model no corpo multipart.").addText(
      (text) => text.setPlaceholder("whisper-large-v3").setValue(this.plugin.settings.model).onChange(async (value) => {
        this.plugin.settings.model = value.trim();
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("Idioma (opcional)").setDesc("Campo language para o backend (ex.: pt, en).").addText(
      (text) => text.setPlaceholder("pt").setValue(this.plugin.settings.language).onChange(async (value) => {
        this.plugin.settings.language = value.trim();
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("Enviar como multipart/form-data").setDesc("Se desativado, envia o blob bin\xE1rio com Content-Type audio/wav.").addToggle(
      (toggle) => toggle.setValue(this.plugin.settings.useFormData).onChange(async (value) => {
        this.plugin.settings.useFormData = value;
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("Campo do arquivo (form-data)").setDesc("Nome do campo multipart que receber\xE1 o \xE1udio.").addText(
      (text) => text.setPlaceholder("file").setValue(this.plugin.settings.fileField).onChange(async (value) => {
        this.plugin.settings.fileField = value || "file";
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("Campo do texto na resposta JSON").setDesc('Nome do campo com a transcri\xE7\xE3o (fallback para "transcript").').addText(
      (text) => text.setPlaceholder("text").setValue(this.plugin.settings.textField).onChange(async (value) => {
        this.plugin.settings.textField = value || "text";
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("Dura\xE7\xE3o do chunk (ms)").setDesc("Tempo de corte; valores menores enviam mais requisi\xE7\xF5es.").addText(
      (text) => text.setPlaceholder("4000").setValue(String(this.plugin.settings.chunkMs)).onChange(async (value) => {
        const num = Number(value);
        this.plugin.settings.chunkMs = Number.isFinite(num) && num > 500 ? num : 4e3;
        await this.plugin.saveSettings();
      })
    );
  }
};
